# Platform Engineering Key Design Patterns (Common-Sensical)
Cloud-scale highly available distributed systems are very complex to design & build out. These systems are typically designed to provide key features such as high-availability/failover, scalability/elasticity, security and portability. Goal is to leverage the following well-proven design patterns as part of the design and build out of **Platform Engineering** initiative - **Standing on the Shoulders of Giants** by learning from the prior experinces of system developers.
- **Availability/Fault-Tolerance**: Cloud platform addresses highly availability and failovers both at application and infrastructure services level.
  - **Circuit-Breakers Pattern**: Electrical fuses prevent fires when a circuit that is connected to the electrical grid starts drawing a high amount of power which causes the wires to heat up and combust. Similar to electrical fuses, circuit breaker design pattern is a fail-first mechanism that shuts down the circuit, request/response relationship or a service in order to prevent bigger failures. A simplistic implementation of this design pattern may be a simple counter that records success and failure states of a circuit along with a timestamp and calculates the consecutive number of failures.

      One can simply apply a wrapper component around potentially dangerous operations (typically outbound/egress) to circumvent calls when the system is not healthy. This is different versus retries as circuit brakers exist to prevent operations rather than re-execute them. 
  - **Bulkhead Pattern**: Bulkhead pattern exhibits a principle of damage containment by partitioning the overall system. With the replicated stateless services, each replica is entirely homogeneous and capable of serving every request. In contrast to replicated services, with sharded services, each replica, or shard, is only capable of serving a subset of all requests. A load-balancing node, or root, is responsible for examining each request and distributing each request to the appropriate shard or shards for processing.
  - Use probes correctly to detect and automatically recover from failures.
  - Make the application & infrastructure components fail hard (crashing), fast (as soon as a problem occurs), and loudly (with informative error messages in their logs). Doing so prevents data from being stuck in a strange state in the failed application and allows routing of traffic only to healthy component instances, and also provides all the information needed for root cause analysis.

- **Scalability**: Cloud platform provides an exteremely elastic environment by enabling horizontal/vertical scaling of workloads on the basis of their resource utilizations reaching the certain desired threshold/s. key goal is to enable automatic scaling to ensure overall capacity management.
   - **Stateless Services**: ​Cloud-native systems typically run multiple instances of a component, to ensure high availability and scalability. Such systems consist of components that depend on the underlying platform and infrastructure for scaling, automation, capacity allocation, failure handling, restarts, service discovery, and so forth.

     Because cloud-native systems make scaling and operations of its components significantly easier, it is highly advisable to have the components of the system to be stateless versus stateful. ***Goal is to have majority of the components of the overall architecture to be stateless, and depend on a few stateful services (data stores) to manage their application state***.
   - **Observability/Monitoring**: ​Application & Infrastructure services are well prepared for observability/monitoring​, possibly using Ambassador design pattern.
  - **Replicated Load-Balanced Services Pattern**: In such a service, every server is identical to every other server (Stateless Services) and all are capable of supporting traffic. Stateless services are ones that don’t require saved state to operate correctly. In the simplest stateless applications, even individual requests may be routed to separate instances of the service.
  
     Examples of stateless services include things like static content servers and complex middleware systems that receive and aggregate responses from numerous different backend systems. This pattern consists of a scalable number of servers with a load balancer in front of them. The load balancer is typically either completely round-robin or uses some form of session stickiness.
  - **Scatter/Gather Pattern**: Earlier we covered patterns that replicate for scalability in terms of the number of requests processed per second (the stateless replicated pattern), as well as scalability for the size of the data (the sharded data pattern). The scatter/gather pattern, on the other hand, uses replication for scalability in terms of time. Specifically, the scatter/gather pattern allows you to achieve parallelism in servicing requests, enabling you to service them significantly faster than one could if you had to service them sequentially.

    Scatter/gather is quite useful when you have a large amount of mostly independent processing that is needed to handle a particular request. Scatter/gather can be seen as sharding the computation necessary to service the request, rather than sharding the data (although data sharding may be part of it as well).
- **Security**: Platform addresses security at various levels: cluster, application and network. The API endpoints are secured through transport layer security (TLS/mTLS).
- **Portability**: Platform enables portability in terms of operating system choices, processor architectures (either virtual machines or bare metal), cloud providers, and various container runtimes, besides Docker, can also be added. It also supports workloads across hybrid (private and public cloud) or multi-cloud environments. This, in turn, also supports availability zone fault tolerance within a single cloud provider.

  Portability requires a common abstraction (Kubernetes Pod like) across all types of workloads (including infrastructure workloads). Such an abstraction has profound implications as it enables overall lifecycle management across all workload types in a portable manner.
- **General Design Patterns**
  - **Side-Car**: In order to provide Modularity and Reusability. in the sidecar pattern, the secondary container enhances the main application (typically containerized) by providing new functionality. The sidecar shares the same life cycle as the parent application, being created and retired alongside the parent. The sidecar pattern is typically made up of two containers. The first is the application container. It contains the core logic for the application. Without this container, the application would not exist. In addition to the application container, there is a sidecar container.
  
    The role of the sidecar is to augment and improve the application container, often without the application container’s knowledge. In its simplest form, a sidecar container can be used to add functionality to a container that might otherwise be difficult to improve. Sidecar containers are co-scheduled onto the same machine via an atomic container group. In addition to being scheduled on the same machine, the application container and sidecar container share a number of resources, including parts of the filesystem, hostname and network, and many other namespaces. Typical usage of this design pattern is the following:
    - Security/SSL-Termination
    - Obserability
    - Logging
    - Debugging
  - **Ambassador Pattern**: Ambassador design pattern is typically used for proxying outbound communication to and from a main container. For example, application maybe speaking the memcache protocol using a twemproxy ambassador. The application believes that it is simply talking to a single memcache on localhost, but actually twemproxy is sharding the requests across a distributed installation of multiple memcache nodes elsewhere in the cluster. Typical usage of this design pattern is the following:
    - Service Discovery/Brokering 
  - **Adapter**: Real-world application development is a heterogeneous, hybrid exercise. Some parts of your application might be written from scratch by your team, some supplied by vendors, and some might consist entirely of off-the-shelf open source or proprietary software that you consume as precompiled binary. The net effect of this heterogeneity is that any real-world application you deploy will have been written in a variety of languages, with a variety of conventions for logging, monitoring, and other common services. Yet, to effectively monitor and operate your application, you need common interfaces. When each application provides metrics using a different format and interface, it is very difficult to collect all of those metrics in a single place for visualization and alerting. This is where the adapter pattern is relevant.

    The adapter pattern uses a secondary container to standardise external interfaces. In contrast to the ambassador pattern, which presents an application with a simplified view of the outside world, adapters present the outside world with a simplified, homogenized view of an application.They do this by standardizing output and interfaces across multiple containers.Typical usage of this design pattern is the following:
    - Standardise log formats
    - Provide common metrics for applications
  - **Ownership Election**: In the context of a single server, ownership is generally straightforward to achieve because there is only a single application that is establishing ownership, and it can use well-established in-process locks to ensure that only a single actor owns a particular shard or context. However, restricting ownership to a single application limits scalability, since the task can’t be replicated, and reliability, since if the task fails, it is unavailable for a period of time.
 
    For example, in a highly available cloud-scale deployment of Kubernetes, there are multiple replicas of the scheduler but only one replica is actively making scheduling decisions. Further, once it becomes the active scheduler, it remains the active scheduler until that process fails for some reason. Consequently, when ownership is required in the system, one needs to develop a distributed system for establishing ownership.
  
    There are two ways to implement this master election. The first option is to implement a distributed consensus algorithm like Paxos or RAFT, which is a very complex undertaking to implement. Implementing one of these algorithms is akin to implementing locks on top of assembly code compare-and-swap instructions. Fortunately, there are a large number of distributed key-value stores that have implemented such consensus algorithms for you. At a general level, these systems provide a replicated, reliable data store and the primitives necessary to build more complicated locking and election abstractions on top. Examples of these distributed stores include etcd, ZooKeeper, and consul.